{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aad3a84",
   "metadata": {},
   "source": [
    "## Process All LightGBM Prediction Files\n",
    "\n",
    "Add original_song_id, original_msno, artist_name, and artist_gender to all LightGBM prediction files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7e54f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PROCESSING ALL LIGHTGBM PREDICTION FILES\n",
      "============================================================\n",
      "\n",
      "Found 10 LightGBM prediction files:\n",
      "  - lgb_0.85401_seed85.csv\n",
      "  - lgb_0.85414_seed121.csv\n",
      "  - lgb_0.85414_seed25.csv\n",
      "  - lgb_0.85420_seed61.csv\n",
      "  - lgb_0.85420_seed73.csv\n",
      "  - lgb_0.85421_seed37.csv\n",
      "  - lgb_0.85423_seed97.csv\n",
      "  - lgb_0.85443_seed49.csv\n",
      "  - lgb_0.85476_seed109.csv\n",
      "  - lgb_0.85502_seed13.csv\n",
      "\n",
      "Output directory: lgb_mapped\n"
     ]
    }
   ],
   "source": [
    "# Process all LightGBM prediction files\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PROCESSING ALL LIGHTGBM PREDICTION FILES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get all CSV files in temp_lgb folder (excluding summary files)\n",
    "lgb_files = glob.glob('temp_lgb/*.csv')\n",
    "lgb_files = [f for f in lgb_files if 'summary' not in os.path.basename(f)]\n",
    "lgb_files.sort()\n",
    "\n",
    "print(f\"\\nFound {len(lgb_files)} LightGBM prediction files:\")\n",
    "for f in lgb_files:\n",
    "    print(f\"  - {os.path.basename(f)}\")\n",
    "\n",
    "# Create output directory\n",
    "output_dir = 'lgb_mapped'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"\\nOutput directory: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c92b09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RECONSTRUCTING LABEL ENCODER MAPPINGS\n",
      "============================================================\n",
      "\n",
      "Loading source data to reconstruct mappings...\n",
      "Created song_id mapping: 419,839 unique songs\n",
      "Created msno mapping: 34,403 unique members\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Reconstruct the song_id and msno mappings\n",
    "# The label encoder was fit on train['song_id'] and test['song_id'] from source_data\n",
    "# We need to get the unique song_ids and msnos in the order they were encoded\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RECONSTRUCTING LABEL ENCODER MAPPINGS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nLoading source data to reconstruct mappings...\")\n",
    "train_source = pd.read_csv('input/training/source_data/train.csv')\n",
    "test_source = pd.read_csv('input/training/source_data/test.csv')\n",
    "\n",
    "# Get all unique song_ids in the order they appear (LabelEncoder sorts unique values)\n",
    "all_song_ids = pd.concat([train_source['song_id'], test_source['song_id']]).unique()\n",
    "all_song_ids_sorted = sorted(all_song_ids)\n",
    "\n",
    "# Create mapping: encoded_id -> original_song_id\n",
    "song_id_mapping = pd.DataFrame({\n",
    "    'encoded_song_id': range(len(all_song_ids_sorted)),\n",
    "    'original_song_id': all_song_ids_sorted\n",
    "})\n",
    "\n",
    "print(f\"Created song_id mapping: {len(song_id_mapping):,} unique songs\")\n",
    "\n",
    "# Get all unique msnos\n",
    "all_msnos = pd.concat([train_source['msno'], test_source['msno']]).unique()\n",
    "all_msnos_sorted = sorted(all_msnos)\n",
    "\n",
    "# Create mapping: encoded_msno -> original_msno\n",
    "msno_mapping = pd.DataFrame({\n",
    "    'encoded_msno': range(len(all_msnos_sorted)),\n",
    "    'original_msno': all_msnos_sorted\n",
    "})\n",
    "\n",
    "print(f\"Created msno mapping: {len(msno_mapping):,} unique members\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "042fa3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading songs and artists data...\n",
      "Loaded songs.csv: 2,296,320 rows\n",
      "Loaded artists.csv: 40,582 rows\n",
      "Songs with artist info: 812,557 / 2,296,320\n",
      "Sample:\n",
      "                                        song_id       artist_name  \\\n",
      "0  CXoTN1eb7AI+DntdU1vbcwGRV4SCIDxZu+YD8JP8r4E=  張信哲 (Jeff Chang)   \n",
      "1  o0kFgae9QtnYgRkVPqLJwa05zIhRlUjfF7O1tDw0ZDU=         BLACKPINK   \n",
      "2  DwVvVurfpuz+XPuFvucclVQEyPqcpUkHR0ne1RQzPs0=      SUPER JUNIOR   \n",
      "3  dKMBWoZyScdxSkihKG+Vf47nc18N9q4m58+b4e7dSSE=             S.H.E   \n",
      "4  W3bqWd3T+VeHFzHAUfARgW9AvVRaF4N5Yzm4Mr6Eo/o=              貴族精選   \n",
      "\n",
      "  artist_gender  \n",
      "0          Male  \n",
      "1           NaN  \n",
      "2           NaN  \n",
      "3           NaN  \n",
      "4          Male  \n"
     ]
    }
   ],
   "source": [
    "# Load songs and artists data for mapping\n",
    "print(\"\\nLoading songs and artists data...\")\n",
    "songs_original = pd.read_csv('input/training/source_data/songs.csv')\n",
    "artists_original = pd.read_csv('input/training/source_data/artists.csv')\n",
    "\n",
    "print(f\"Loaded songs.csv: {len(songs_original):,} rows\")\n",
    "print(f\"Loaded artists.csv: {len(artists_original):,} rows\")\n",
    "\n",
    "# Create a mapping from original_song_id to artist_name and gender\n",
    "# First, join songs with artists\n",
    "songs_with_artists = songs_original[['song_id', 'artist_name']].merge(\n",
    "    artists_original[['artist_name', 'gender']],\n",
    "    on='artist_name',\n",
    "    how='left',\n",
    "    suffixes=('', '_artist')\n",
    ")\n",
    "\n",
    "# Rename gender column to avoid confusion\n",
    "songs_with_artists = songs_with_artists.rename(columns={'gender': 'artist_gender'})\n",
    "\n",
    "print(f\"Songs with artist info: {songs_with_artists['artist_gender'].notna().sum():,} / {len(songs_with_artists):,}\")\n",
    "print(f\"Sample:\\n{songs_with_artists.head()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eff0f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PROCESSING FILES\n",
      "============================================================\n",
      "\n",
      "Processing: lgb_0.85401_seed85.csv\n",
      "  Loaded: 1,411,395 rows\n",
      "  ✓ Saved to: lgb_mapped/lgb_0.85401_seed85.csv\n",
      "    - Original song_id mapped: 1,411,395 / 1,411,395 (100.0%)\n",
      "    - Original msno mapped: 1,411,395 / 1,411,395 (100.0%)\n",
      "    - Artist name mapped: 1,411,372 / 1,411,395 (100.0%)\n",
      "    - Artist gender mapped: 954,163 / 1,411,395 (67.6%)\n",
      "\n",
      "Processing: lgb_0.85414_seed121.csv\n",
      "  Loaded: 1,411,395 rows\n",
      "  ✓ Saved to: lgb_mapped/lgb_0.85414_seed121.csv\n",
      "    - Original song_id mapped: 1,411,395 / 1,411,395 (100.0%)\n",
      "    - Original msno mapped: 1,411,395 / 1,411,395 (100.0%)\n",
      "    - Artist name mapped: 1,411,376 / 1,411,395 (100.0%)\n",
      "    - Artist gender mapped: 954,331 / 1,411,395 (67.6%)\n",
      "\n",
      "Processing: lgb_0.85414_seed25.csv\n",
      "  Loaded: 1,411,395 rows\n",
      "  ✓ Saved to: lgb_mapped/lgb_0.85414_seed25.csv\n",
      "    - Original song_id mapped: 1,411,395 / 1,411,395 (100.0%)\n",
      "    - Original msno mapped: 1,411,395 / 1,411,395 (100.0%)\n",
      "    - Artist name mapped: 1,411,375 / 1,411,395 (100.0%)\n",
      "    - Artist gender mapped: 954,003 / 1,411,395 (67.6%)\n",
      "\n",
      "Processing: lgb_0.85420_seed61.csv\n",
      "  Loaded: 1,411,395 rows\n",
      "  ✓ Saved to: lgb_mapped/lgb_0.85420_seed61.csv\n",
      "    - Original song_id mapped: 1,411,395 / 1,411,395 (100.0%)\n",
      "    - Original msno mapped: 1,411,395 / 1,411,395 (100.0%)\n",
      "    - Artist name mapped: 1,411,367 / 1,411,395 (100.0%)\n",
      "    - Artist gender mapped: 952,875 / 1,411,395 (67.5%)\n",
      "\n",
      "Processing: lgb_0.85420_seed73.csv\n",
      "  Loaded: 1,411,395 rows\n",
      "  ✓ Saved to: lgb_mapped/lgb_0.85420_seed73.csv\n",
      "    - Original song_id mapped: 1,411,395 / 1,411,395 (100.0%)\n",
      "    - Original msno mapped: 1,411,395 / 1,411,395 (100.0%)\n",
      "    - Artist name mapped: 1,411,377 / 1,411,395 (100.0%)\n",
      "    - Artist gender mapped: 954,947 / 1,411,395 (67.7%)\n",
      "\n",
      "Processing: lgb_0.85421_seed37.csv\n",
      "  Loaded: 1,411,395 rows\n",
      "  ✓ Saved to: lgb_mapped/lgb_0.85421_seed37.csv\n",
      "    - Original song_id mapped: 1,411,395 / 1,411,395 (100.0%)\n",
      "    - Original msno mapped: 1,411,395 / 1,411,395 (100.0%)\n",
      "    - Artist name mapped: 1,411,375 / 1,411,395 (100.0%)\n",
      "    - Artist gender mapped: 954,743 / 1,411,395 (67.6%)\n",
      "\n",
      "Processing: lgb_0.85423_seed97.csv\n",
      "  Loaded: 1,411,395 rows\n",
      "  ✓ Saved to: lgb_mapped/lgb_0.85423_seed97.csv\n",
      "    - Original song_id mapped: 1,411,395 / 1,411,395 (100.0%)\n",
      "    - Original msno mapped: 1,411,395 / 1,411,395 (100.0%)\n",
      "    - Artist name mapped: 1,411,372 / 1,411,395 (100.0%)\n",
      "    - Artist gender mapped: 953,901 / 1,411,395 (67.6%)\n",
      "\n",
      "Processing: lgb_0.85443_seed49.csv\n",
      "  Loaded: 1,411,395 rows\n",
      "  ✓ Saved to: lgb_mapped/lgb_0.85443_seed49.csv\n",
      "    - Original song_id mapped: 1,411,395 / 1,411,395 (100.0%)\n",
      "    - Original msno mapped: 1,411,395 / 1,411,395 (100.0%)\n",
      "    - Artist name mapped: 1,411,371 / 1,411,395 (100.0%)\n",
      "    - Artist gender mapped: 954,936 / 1,411,395 (67.7%)\n",
      "\n",
      "Processing: lgb_0.85476_seed109.csv\n",
      "  Loaded: 1,411,395 rows\n",
      "  ✓ Saved to: lgb_mapped/lgb_0.85476_seed109.csv\n",
      "    - Original song_id mapped: 1,411,395 / 1,411,395 (100.0%)\n",
      "    - Original msno mapped: 1,411,395 / 1,411,395 (100.0%)\n",
      "    - Artist name mapped: 1,411,378 / 1,411,395 (100.0%)\n",
      "    - Artist gender mapped: 953,752 / 1,411,395 (67.6%)\n",
      "\n",
      "Processing: lgb_0.85502_seed13.csv\n",
      "  Loaded: 1,411,395 rows\n",
      "  ✓ Saved to: lgb_mapped/lgb_0.85502_seed13.csv\n",
      "    - Original song_id mapped: 1,411,395 / 1,411,395 (100.0%)\n",
      "    - Original msno mapped: 1,411,395 / 1,411,395 (100.0%)\n",
      "    - Artist name mapped: 1,411,372 / 1,411,395 (100.0%)\n",
      "    - Artist gender mapped: 953,725 / 1,411,395 (67.6%)\n",
      "\n",
      "============================================================\n",
      "COMPLETE: Processed 10 files\n",
      "Output directory: lgb_mapped/\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Process each LightGBM file\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PROCESSING FILES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "processed_count = 0\n",
    "for file_path in lgb_files:\n",
    "    filename = os.path.basename(file_path)\n",
    "    print(f\"\\nProcessing: {filename}\")\n",
    "    \n",
    "    # Load the prediction file\n",
    "    df_lgb = pd.read_csv(file_path)\n",
    "    print(f\"  Loaded: {len(df_lgb):,} rows\")\n",
    "    \n",
    "    # Map encoded song_id to original_song_id\n",
    "    df_lgb_mapped = df_lgb.merge(\n",
    "        song_id_mapping,\n",
    "        left_on='song_id',\n",
    "        right_on='encoded_song_id',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Map encoded msno to original_msno\n",
    "    df_lgb_mapped = df_lgb_mapped.merge(\n",
    "        msno_mapping,\n",
    "        left_on='msno',\n",
    "        right_on='encoded_msno',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Add artist_name and gender using original_song_id\n",
    "    df_lgb_mapped = df_lgb_mapped.merge(\n",
    "        songs_with_artists[['song_id', 'artist_name', 'artist_gender']],\n",
    "        left_on='original_song_id',\n",
    "        right_on='song_id',\n",
    "        how='left',\n",
    "        suffixes=('', '_song')\n",
    "    )\n",
    "    \n",
    "    # Drop the intermediate columns we don't need\n",
    "    columns_to_drop = ['encoded_song_id', 'encoded_msno', 'song_id_song', \n",
    "                       'original_index', 'song_id', 'msno']\n",
    "    df_lgb_mapped = df_lgb_mapped.drop(columns=[col for col in columns_to_drop if col in df_lgb_mapped.columns])\n",
    "    \n",
    "    other_cols = [col for col in df_lgb_mapped.columns \n",
    "                  if col not in ['prediction', 'ground_truth_target']]\n",
    "    column_order = other_cols + ['prediction', 'ground_truth_target']\n",
    "    df_lgb_mapped = df_lgb_mapped[column_order]\n",
    "    \n",
    "    # Save to output directory\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    df_lgb_mapped.to_csv(output_path, index=False)\n",
    "    \n",
    "    # Print summary\n",
    "    mapped_songs = df_lgb_mapped['original_song_id'].notna().sum()\n",
    "    mapped_members = df_lgb_mapped['original_msno'].notna().sum()\n",
    "    mapped_artists = df_lgb_mapped['artist_name'].notna().sum()\n",
    "    mapped_gender = df_lgb_mapped['artist_gender'].notna().sum()\n",
    "    \n",
    "    print(f\"  ✓ Saved to: {output_path}\")\n",
    "    print(f\"    - Original song_id mapped: {mapped_songs:,} / {len(df_lgb_mapped):,} ({mapped_songs/len(df_lgb_mapped)*100:.1f}%)\")\n",
    "    print(f\"    - Original msno mapped: {mapped_members:,} / {len(df_lgb_mapped):,} ({mapped_members/len(df_lgb_mapped)*100:.1f}%)\")\n",
    "    print(f\"    - Artist name mapped: {mapped_artists:,} / {len(df_lgb_mapped):,} ({mapped_artists/len(df_lgb_mapped)*100:.1f}%)\")\n",
    "    print(f\"    - Artist gender mapped: {mapped_gender:,} / {len(df_lgb_mapped):,} ({mapped_gender/len(df_lgb_mapped)*100:.1f}%)\")\n",
    "    \n",
    "    processed_count += 1\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"COMPLETE: Processed {processed_count} files\")\n",
    "print(f\"Output directory: {output_dir}/\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81f588ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying processed file...\n",
      "\n",
      "Sample file: lgb_0.85401_seed85.csv\n",
      "Columns: ['id', 'prediction', 'ground_truth_target', 'original_song_id', 'original_msno', 'artist_name', 'artist_gender']\n",
      "\n",
      "First few rows:\n",
      "   id                              original_song_id  \\\n",
      "0   0  qD/QQKjFB3am2ZYMF3fNgOIPrIuUezHVQobMJk5VduY=   \n",
      "1   1  beJIbbUTXpeZGLp4A8xLGRCAH6vf8EG3qGGSkJ2xtpM=   \n",
      "2   2  auorhKXu9I04OVrLaDysoWEY/XSjmEcdgBRWHrLbbX8=   \n",
      "3   3  3ZVFKlYjOLiyLGW2iuhN/Ca+E11w/OB7z1YFkUdnArA=   \n",
      "4   4  D1tFsBLd9VWbonfb6Vek0BI2EJB6udLOuV/x+ptYpOI=   \n",
      "5   5  HjD0DJh8lSSclFWoxwslnYwZkNeqMsxE+A2RqXpM8OQ=   \n",
      "6   6  M+GLP5Bp1uC2RPh3lICfwnaf4l1qTboG4piMZsSB46M=   \n",
      "7   7  BYBO2FYmzfeyuGeIV57iifEhQ4l3FjmYj2kzkIwubRE=   \n",
      "8   8  MBCMb17fx7JWgOxzuAmB8CjSHp1xhBZJD56eqr2thiw=   \n",
      "9   9  dDYizzhBq3x9uVKTsiM2FTzDMAmiR+8AsmVrWG7aOOM=   \n",
      "\n",
      "                                  original_msno        artist_name  \\\n",
      "0  Dp/J1U1bEvNzB6OEKLtrJZSfJNedtuQh7/ZgjmZdjgM=   戴愛玲 (Ailing Tai)   \n",
      "1  4m5Sn66p8UPrX7DJkBD5xfdHePZEI9Nui6iDtSr5kno=   任賢齊 (Richie Jen)   \n",
      "2  /5/Mq5hPzT0Tbf0aY1CeSapADLCVz3v/II8A69Hk4Gg=             ANOHNI   \n",
      "3  VDdpi4A9tTo2XoHPnnMakR1p/k1dLxHL3om7Hiezq/U=  王力宏 (Leehom Wang)   \n",
      "4  lSkUSnCm60kDLdEsnAVp6jwr2HkyIhDCEZLX82djjHg=       林俊傑 (JJ Lin)   \n",
      "5  Ah7O+2NWyNAwtHy874p2WjR4vdlidLYnPW1oeX97Qzg=              globe   \n",
      "6  Z75En2y0vBrKTwJ3taDYLpu/xDQLnYcEGKgxaqVtPwM=    Various Artists   \n",
      "7  sHxE+oZY8YrNIaSd7v271O6YBPlmDWWTXBL5tdNE8/c=            宮崎駿映畫音樂   \n",
      "8  pPeDfiTzGXHssfeQVIVlwT4/eSCXPT49pOdaNGEDTQE=   Childish Gambino   \n",
      "9  V8E12NF/LQQSzshmEz4hKh3+cuBnWL3EUTnwpJ2qhSE=     王菲 (Faye Wong)   \n",
      "\n",
      "  artist_gender  prediction  ground_truth_target  \n",
      "0        Female    0.594434                    1  \n",
      "1          Male    0.372872                    0  \n",
      "2        Female    0.485421                    0  \n",
      "3          Male    0.022465                    0  \n",
      "4          Male    0.672345                    0  \n",
      "5           NaN    0.227357                    0  \n",
      "6           NaN    0.689245                    0  \n",
      "7          Male    0.419937                    0  \n",
      "8          Male    0.571872                    0  \n",
      "9        Female    0.096991                    0  \n"
     ]
    }
   ],
   "source": [
    "# Verify one of the processed files\n",
    "print(\"\\nVerifying processed file...\")\n",
    "sample_file = os.path.join(output_dir, os.path.basename(lgb_files[0]))\n",
    "df_sample = pd.read_csv(sample_file)\n",
    "print(f\"\\nSample file: {os.path.basename(sample_file)}\")\n",
    "print(f\"Columns: {df_sample.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df_sample[['id', 'original_song_id', 'original_msno', 'artist_name', 'artist_gender', 'prediction', 'ground_truth_target']].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c76d054",
   "metadata": {},
   "source": [
    "## Process All Neural Network Prediction Files\n",
    "\n",
    "Add original_song_id, original_msno, artist_name, and artist_gender to all NN prediction files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ed6236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all Neural Network prediction files\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PROCESSING ALL NEURAL NETWORK PREDICTION FILES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get all CSV files in temp_nn folder (excluding summary files and models directory)\n",
    "nn_files = glob.glob('temp_nn/*.csv')\n",
    "nn_files = [f for f in nn_files if 'summary' not in os.path.basename(f)]\n",
    "nn_files.sort()\n",
    "\n",
    "print(f\"\\nFound {len(nn_files)} Neural Network prediction files:\")\n",
    "for f in nn_files:\n",
    "    print(f\"  - {os.path.basename(f)}\")\n",
    "\n",
    "# Create output directory\n",
    "output_dir_nn = 'nn_mapped'\n",
    "os.makedirs(output_dir_nn, exist_ok=True)\n",
    "print(f\"\\nOutput directory: {output_dir_nn}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083b9605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each Neural Network file\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PROCESSING NN FILES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "processed_count_nn = 0\n",
    "for file_path in nn_files:\n",
    "    filename = os.path.basename(file_path)\n",
    "    print(f\"\\nProcessing: {filename}\")\n",
    "    \n",
    "    # Load the prediction file\n",
    "    df_nn = pd.read_csv(file_path)\n",
    "    print(f\"  Loaded: {len(df_nn):,} rows\")\n",
    "    \n",
    "    # Map encoded song_id to original_song_id\n",
    "    df_nn_mapped = df_nn.merge(\n",
    "        song_id_mapping,\n",
    "        left_on='song_id',\n",
    "        right_on='encoded_song_id',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Map encoded msno to original_msno\n",
    "    df_nn_mapped = df_nn_mapped.merge(\n",
    "        msno_mapping,\n",
    "        left_on='msno',\n",
    "        right_on='encoded_msno',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Add artist_name and gender using original_song_id\n",
    "    df_nn_mapped = df_nn_mapped.merge(\n",
    "        songs_with_artists[['song_id', 'artist_name', 'artist_gender']],\n",
    "        left_on='original_song_id',\n",
    "        right_on='song_id',\n",
    "        how='left',\n",
    "        suffixes=('', '_song')\n",
    "    )\n",
    "    \n",
    "    # Drop the intermediate columns we don't need\n",
    "    columns_to_drop = ['encoded_song_id', 'encoded_msno', 'song_id_song', \n",
    "                       'original_index', 'song_id', 'msno']\n",
    "    df_nn_mapped = df_nn_mapped.drop(columns=[col for col in columns_to_drop if col in df_nn_mapped.columns])\n",
    "    \n",
    "    # Reorder columns: put prediction and ground_truth_target last\n",
    "    other_cols = [col for col in df_nn_mapped.columns \n",
    "                  if col not in ['prediction', 'ground_truth_target']]\n",
    "    column_order = other_cols + ['prediction', 'ground_truth_target']\n",
    "    df_nn_mapped = df_nn_mapped[column_order]\n",
    "    \n",
    "    # Save to output directory\n",
    "    output_path = os.path.join(output_dir_nn, filename)\n",
    "    df_nn_mapped.to_csv(output_path, index=False)\n",
    "    \n",
    "    # Print summary\n",
    "    mapped_songs = df_nn_mapped['original_song_id'].notna().sum()\n",
    "    mapped_members = df_nn_mapped['original_msno'].notna().sum()\n",
    "    mapped_artists = df_nn_mapped['artist_name'].notna().sum()\n",
    "    mapped_gender = df_nn_mapped['artist_gender'].notna().sum()\n",
    "    \n",
    "    print(f\"  ✓ Saved to: {output_path}\")\n",
    "    print(f\"    - Original song_id mapped: {mapped_songs:,} / {len(df_nn_mapped):,} ({mapped_songs/len(df_nn_mapped)*100:.1f}%)\")\n",
    "    print(f\"    - Original msno mapped: {mapped_members:,} / {len(df_nn_mapped):,} ({mapped_members/len(df_nn_mapped)*100:.1f}%)\")\n",
    "    print(f\"    - Artist name mapped: {mapped_artists:,} / {len(df_nn_mapped):,} ({mapped_artists/len(df_nn_mapped)*100:.1f}%)\")\n",
    "    print(f\"    - Artist gender mapped: {mapped_gender:,} / {len(df_nn_mapped):,} ({mapped_gender/len(df_nn_mapped)*100:.1f}%)\")\n",
    "    \n",
    "    processed_count_nn += 1\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"COMPLETE: Processed {processed_count_nn} NN files\")\n",
    "print(f\"Output directory: {output_dir_nn}/\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5490edb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify one of the processed NN files\n",
    "print(\"\\nVerifying processed NN file...\")\n",
    "sample_file_nn = os.path.join(output_dir_nn, os.path.basename(nn_files[0]))\n",
    "df_sample_nn = pd.read_csv(sample_file_nn)\n",
    "print(f\"\\nSample file: {os.path.basename(sample_file_nn)}\")\n",
    "print(f\"Columns: {df_sample_nn.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df_sample_nn.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
